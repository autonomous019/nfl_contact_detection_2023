# -*- coding: utf-8 -*-
"""train-data-contact-experiment-cnn-baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xGw5Z6Qdbv40VHM3iuZFD4TSnATJ3N7I
"""

!pip install timm

# Import from GoogleDrive

from google.colab import drive
import os

drive.mount('/content/gdrive')
os.chdir("//content/gdrive/MyDrive/nfl-player-contact-detection/")

data_dir = "/content/gdrive/My Drive/nfl-player-contact-detection/"
'''
data_dir = "../input/"
OUTPUT_DIR = './'
'''

import os
import sys
sys.path.append(data_dir + 'pytorch-image-models-master')
import glob
import numpy as np
import pandas as pd
import random
import math
import gc
import cv2
from tqdm import tqdm
import time
from functools import lru_cache
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import matplotlib.pyplot as plt
from sklearn.metrics import matthews_corrcoef
import shutil

'''
out-of-the box algo fails badly on contact=1, most of positive score which is low, .671, is from contact = 0. 
did learn how to calculate euclideans on the fly more efficiently though. 
out-of-the-box is no-go

next steps:
1. try training my own model 
2. find clever tricks using open cv2 and yolo

kaggle files:
sub1 1 694 eucl < 1.0 there are 570 p-to-p with like 99% being contact=1, so in G cases the model only adds another 124 contact=1, which is off by about 10x, should be more like 1240. 
sub 2 949
sub 3 942

filtered1 2585 = 1
filtered2 = 
filtered3 = 2585
'''

CFG = {
    'seed': 42,
    'model': 'resnet50',
    'img_size': 256,
    'epochs': 10,
    'train_bs': 100, 
    'valid_bs': 64,
    'lr': 1e-3, 
    'weight_decay': 1e-6,
    'num_workers': 2
}

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed_everything(CFG['seed'])
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def expand_contact_id(df):
    """
    Splits out contact_id into seperate columns.
    """
    df["game_play"] = df["contact_id"].str[:12]
    df["step"] = df["contact_id"].str.split("_").str[-3].astype("int")
    df["nfl_player_id_1"] = df["contact_id"].str.split("_").str[-2]
    df["nfl_player_id_2"] = df["contact_id"].str.split("_").str[-1]
    return df

labels = expand_contact_id(pd.read_csv(data_dir + "train_labels.csv"))

test_tracking = pd.read_csv(data_dir + "train_player_tracking.csv")

test_helmets = pd.read_csv(data_dir + "train_baseline_helmets.csv")

test_video_metadata = pd.read_csv(data_dir + "train_video_metadata.csv")
labels.head()

print("Labels")
print(len(labels))
print(len(labels.loc[labels['nfl_player_id_2'] == 'G']))
print(len(labels.loc[(labels['nfl_player_id_2'] == 'G') & (labels['contact'] == 1)]))
#print(len(labels.loc[(labels['nfl_player_id_2'] != 'G') & (labels['contact'] == 1)]))
print()

#split the training data into a train and test set
labels_train = labels.iloc[:4000000,:]
labels_test = labels.iloc[4000000:,:]


print("TRAIN")
print("train len: ", len(labels_train))
print("Gs in train: ", len(labels_train.loc[labels_train['nfl_player_id_2'] == 'G']))
print("len of train Gs, contact=1: ", len(labels_train.loc[(labels_train['nfl_player_id_2'] == 'G') & (labels_train['contact'] == 1)]))
print("len of p-to-p, contact=1: ", len(labels_train.loc[(labels_train['nfl_player_id_2'] != 'G') & (labels_train['contact'] == 1)]))
print()
print("TEST")
print("test len: ", len(labels_test))
print("Gs in test: ", len(labels_test.loc[labels_test['nfl_player_id_2'] == 'G']))
print("len of test Gs, contact=1: ", len(labels_test.loc[(labels_test['nfl_player_id_2'] == 'G') & (labels_test['contact'] == 1)]))
print("len of p-to-p, contact=1: ", len(labels_test.loc[(labels_test['nfl_player_id_2'] != 'G') & (labels_test['contact'] == 1)]))

'''
!mkdir -p '/content/gdrive/My Drive/nfl-player-contact-detection/work/frames'

for video in tqdm(test_helmets.video.unique()):
    if 'Endzone2' not in video:
        #!ffmpeg -i /kaggle/input/nfl-player-contact-detection/test/{video} -q:v 2 -f image2 /kaggle/work/frames/{video}_%04d.jpg -hide_banner -loglevel error
        !ffmpeg -i '/content/gdrive/My Drive/nfl-player-contact-detection/test/{video}' -q:v 2 -f image2 '/content/gdrive/My Drive/nfl-player-contact-detection/work/frames/{video}_%04d.jpg' -hide_banner -loglevel error
'''

'''
path_mp0=data_dir + 'train/58168_003392_Sideline.mp4'
path_mp1=data_dir + 'sample1/sample.mp4'
shutil.copy(path_mp0,path_mp1)
'''

def create_features(df, tr_tracking, merge_col="step", use_cols=["x_position", "y_position"]):
    output_cols = []
    df_combo = (
        df.astype({"nfl_player_id_1": "str"})
        .merge(
            tr_tracking.astype({"nfl_player_id": "str"})[
                ["game_play", merge_col, "nfl_player_id",] + use_cols
            ],
            left_on=["game_play", merge_col, "nfl_player_id_1"],
            right_on=["game_play", merge_col, "nfl_player_id"],
            how="left",
        )
        .rename(columns={c: c+"_1" for c in use_cols})
        .drop("nfl_player_id", axis=1)
        .merge(
            tr_tracking.astype({"nfl_player_id": "str"})[
                ["game_play", merge_col, "nfl_player_id"] + use_cols
            ],
            left_on=["game_play", merge_col, "nfl_player_id_2"],
            right_on=["game_play", merge_col, "nfl_player_id"],
            how="left",
        )
        .drop("nfl_player_id", axis=1)
        .rename(columns={c: c+"_2" for c in use_cols})
        .sort_values(["game_play", merge_col, "nfl_player_id_1", "nfl_player_id_2"])
        .reset_index(drop=True)
    )
    output_cols += [c+"_1" for c in use_cols]
    output_cols += [c+"_2" for c in use_cols]
    
    #measuring euclidean distance
    if ("x_position" in use_cols) & ("y_position" in use_cols):
        index = df_combo['x_position_2'].notnull()
        
        distance_arr = np.full(len(index), np.nan)
        tmp_distance_arr = np.sqrt(
            np.square(df_combo.loc[index, "x_position_1"] - df_combo.loc[index, "x_position_2"])
            + np.square(df_combo.loc[index, "y_position_1"]- df_combo.loc[index, "y_position_2"])
        )
        
        distance_arr[index] = tmp_distance_arr
        df_combo['distance'] = distance_arr
        output_cols += ["distance"]
        
    df_combo['G_flug'] = (df_combo['nfl_player_id_2']=="G")
    output_cols += ["G_flug"]
    return df_combo, output_cols


use_cols = [
    'x_position', 'y_position', 'speed', 'distance',
    'direction', 'orientation', 'acceleration', 'sa'
]

test, feature_cols = create_features(labels, test_tracking, use_cols=use_cols)


test

print("Gs ", len(test.loc[test['nfl_player_id_2'] == 'G']))
print("Gs contact=1 ", len(test.loc[(test['nfl_player_id_2'] == 'G') & (test['contact'] == 1)]))
print("not Gs ", len(test.loc[test['nfl_player_id_2'] != 'G']))
print("not Gs contact=1 ", len(test.loc[(test['nfl_player_id_2'] != 'G') & (test['contact'] == 1)]))
print("not Gs distance < 1 ", len(test.loc[(test['nfl_player_id_2'] != 'G') & (test['distance'] <= 2.33)]))
print("not Gs distance < 1 & contact = 1 ", len(test.loc[(test['nfl_player_id_2'] != 'G') & (test['contact'] == 1) & (test['distance'] <= 2.33)]))

"""# **create train train data**"""

train_test, train_feature_cols = create_features(labels_train, test_tracking, use_cols=use_cols)

print("Gs ", len(train_test.loc[train_test['nfl_player_id_2'] == 'G']))
print("Gs contact=1 ", len(train_test.loc[(train_test['nfl_player_id_2'] == 'G') & (train_test['contact'] == 1)]))
print("not Gs ", len(train_test.loc[train_test['nfl_player_id_2'] != 'G']))
print("not Gs contact=1 ", len(train_test.loc[(train_test['nfl_player_id_2'] != 'G') & (train_test['contact'] == 1)]))
print("not Gs distance < 1 ", len(train_test.loc[(train_test['nfl_player_id_2'] != 'G') & (train_test['distance'] <= 1)]))
print("not Gs distance < 1 & contact = 1 ", len(train_test.loc[(train_test['nfl_player_id_2'] != 'G') & (train_test['contact'] == 1) & (train_test['distance'] <= 1)]))

train_test

"""# **create train test data**"""

test_test, test_feature_cols = create_features(labels_test, test_tracking, use_cols=use_cols)

print("Gs ", len(test_test.loc[test_test['nfl_player_id_2'] == 'G']))
print("Gs contact=1 ", len(test_test.loc[(test_test['nfl_player_id_2'] == 'G') & (test_test['contact'] == 1)]))
print("not Gs ", len(test_test.loc[test_test['nfl_player_id_2'] != 'G']))
print("not Gs contact=1 ", len(test_test.loc[(test_test['nfl_player_id_2'] != 'G') & (test_test['contact'] == 1)]))
print("not Gs distance < 1 ", len(test_test.loc[(test_test['nfl_player_id_2'] != 'G') & (test_test['distance'] <= 1)]))
print("not Gs distance < 1 & contact = 1 ", len(test_test.loc[(test_test['nfl_player_id_2'] != 'G') & (test_test['contact'] == 1) & (test_test['distance'] <= 1)]))

test_test

"""# **Create cache of images for each video in train directory**"""

import os
 
# Get the list of all files and directories
path = data_dir + "train/frames"
dir_list = os.listdir(path)
 
print("Files and directories in '", path, "' :")
 
# prints all files
print(len(dir_list))
#print(dir_list)

import cv2
import os
  

for file_name in dir_list:
    filename = file_name
    f_path = data_dir + 'train/' + filename
    print(f_path)
    #print(filename)
    # Read the video from specified path
    cam = cv2.VideoCapture(f_path)
      
    # frame
    currentframe = 1
      
    while(True):

        # reading from frame
        ret,frame = cam.read()
        #print(ret, frame)
      
        if ret:
            # if video is still left continue creating images

            frame_idx = '{:04d}'.format(currentframe)
            #print("framed:" ,frame_idx)
            name = data_dir + 'train/frames/'+filename+'_'+ str(frame_idx) + '.jpg'
            print ('Creating...' + name)
      
            # writing the extracted images
            cv2.imwrite(name, frame)
            
            # increasing counter so that it will
            # show how many frames are created
            currentframe += 1
        else:
            break
      
    # Release all space and windows once done
    cam.release()
    cv2.destroyAllWindows()

"""# **Copy Contact Play Images to train/contact**

**copy only the right frames where contact=1**

don't forget to make adjustments for contact is 1 or 0

there are 60 frames per second, but the sensors operate at 10Hz so that you get a split of every 6 steps is 1/10 of a sec or 10Hz. 
"""

#need to grab img for proper step for game_play and put into train and test directories
# frames = np.array([-4,-3,-2,-1,1,2,3,4])+row[1]
#switch between test_test and train_test for different directories and images
game_plays = test_test[['game_play', 'step', 'contact']].copy()
game_plays = game_plays.drop_duplicates().copy()
copy_files = []
#sample only for non-contact
#game_plays = game_plays.sample(n = 10000).copy() #remove this line for contact = 1
print(len(game_plays))
#create images for train/contact
for c,i in game_plays.iterrows():
  game_play = i['game_play']
  step = i['step']
  contact = i['contact']
  #filter for contact or no-contact
  if contact == 1:
    this_frame = (step/10*59.94+5*59.94)+1
    this_frame = int(this_frame)
    this_frame = '{:04d}'.format(this_frame)
    print(game_play, step, this_frame, contact)
    filename1 = game_play+'_Endzone.mp4_'+this_frame+'.jpg'
    filename2 = game_play+'_Sideline.mp4_'+this_frame+'.jpg'
    filename3 = game_play+'_All29.mp4_'+this_frame+'.jpg'
    path1=data_dir + 'train/frames/'+filename1
    path2=data_dir + 'train/frames/'+filename2
    path3=data_dir + 'train/frames/'+filename3

    destination1=data_dir + 'train/contact/' + filename1
    destination2=data_dir + 'train/contact/' + filename2
    destination3=data_dir + 'train/contact/' + filename3

    print(filename1)
    copy_files.append(filename1)

    #shutil.copy(path1,destination1)
    #shutil.copy(path2,destination2)
    #shutil.copy(path3,destination3)
    if c > 100000:
      break

print(len(copy_files))
print(copy_files)
print()

"""**create contact=1 directory populate with frames**"""



print(len(copy_files))
for i in copy_files:
  file_copy = i
  path1 = 'train/frames/' + file_copy
  destination1 = 'test/contact/' + file_copy
  from os.path import exists
  print(path1)
  file_exists = exists(path1)
  if file_exists:
    shutil.copy(path1,destination1)

import os
 
# Get the list of all files and directories
path = data_dir + "test/contact"
dir_list = os.listdir(path)
 
print("Files and directories in '", path, "' :")
 
# prints all files
print(len(dir_list))
#print(dir_list)

"""**NO-CONTACT**"""

for i in copy_files:
  file_copy = i
  path1 = 'train/frames/' + file_copy
  destination1 = 'train/no-contact/' + file_copy
  from os.path import exists

  file_exists = exists(path1)
  if file_exists:
    shutil.copy(path1,destination1)

import os
 
# Get the list of all files and directories
path = data_dir + "train/no-contact"
dir_list = os.listdir(path)
 
print("Files and directories in '", path, "' :")
 
# prints all files
print(len(dir_list))
#print(dir_list)

"""# **Create Test Contact and No-Contact Images**

creata a random split in train/contact and train/no-contact and copy to test/contact or test/no-contact
"""

import os
 
# Get the list of all files and directories
path = data_dir + "test/"
dir_list = os.listdir(path)
 
print("Files and directories in '", path, "' :")
 
# prints all files
print(len(dir_list))
print(dir_list)

#copy_files.append(filename1)

"""**CONTACT**"""

import os, random, shutil

#copies files from train/contact to test/contact and removes them from train/contact
source="train/contact"
dest="test/contact"
no_of_files=1000

#Using for loop to randomly choose multiple files
'''
for i in range(no_of_files):
    #Variable random_file stores the name of the random file chosen
    random_file=random.choice(os.listdir(source))
    print("%d} %s"%(i+1,random_file))
    source_file="%s/%s"%(source,random_file)
    dest_file=dest
    #"shutil.move" function moves file from one directory to another
    shutil.move(source_file,dest_file)

'''

"""**NO-CONTACT**"""

import os, random, shutil

#copies files from train/no-contact to test/no-contact and removes them from train/contact
source="train/no-contact"
dest="test/no-contact"
no_of_files=1000

#Using for loop to randomly choose multiple files
'''
for i in range(no_of_files):
    #Variable random_file stores the name of the random file chosen
    random_file=random.choice(os.listdir(source))
    print("%d} %s"%(i+1,random_file))
    source_file="%s/%s"%(source,random_file)
    dest_file=dest
    #"shutil.move" function moves file from one directory to another
    shutil.move(source_file,dest_file)
'''

"""# **Create New Dataframes for Test and Train**

create a train dataframe by reading the files in the train/contact directory
append to train dataframe by reading the files in the train/no-contact directory

"""

import os
 
# Get the list of all files and directories
path = data_dir + "train/contact"
dir_list = os.listdir(path)
 
# prints all files
print(len(dir_list))
print(dir_list)

for i in dir_list:
  args = i.split("_")
  #print(args)
  game_id = args[0]
  play_id = args[1]
  view = args[2]
  stepper = args[3]
  stepper = stepper.split(".")
  step = stepper[0]
  #print(game_id, play_id, step)





"""# **split off by euclidean length**"""

#this should be replaced with a df of only the ones that need checked

test_filtered = test.query('not distance>1.0').reset_index(drop=True).copy()
test_filtered['frame'] = (test_filtered['step']/10*59.94+5*59.94).astype('int')+1


print(test_filtered.columns)
test_filtered_contact_ids = test_filtered['contact_id'].tolist()
test_filtered_distances = test_filtered['distance'].tolist()
test_filtered_contacts = test_filtered['contact'].tolist()

test_filtered.to_csv(data_dir + "filtered_google_1.csv", index=False)

test_filtered

#print(len(test_filtered.loc[test_filtered['nfl_player_id_2'] != 'G']))

#contacts_exist = test_filtered.loc[test_filtered['contact'] != '1']

print(len(test_filtered.loc[test_filtered['nfl_player_id_2'] == 'G']))
print(len(test_filtered.loc[(test_filtered['nfl_player_id_2'] == 'G') & (test_filtered['contact'] == 1)]))
print(len(test_filtered.loc[test_filtered['nfl_player_id_2'] != 'G']))
print(len(test_filtered.loc[(test_filtered['nfl_player_id_2'] != 'G') & (test_filtered['contact'] == 1)]))

'''
res = test_filtered.loc[test_filtered['nfl_player_id_2'] != 'G']
#print(res)
contact_true = []
for c,i in res.iterrows():
  contact_id = i['contact_id']
  #print(labels.loc[labels['contact_id'] == contact_id])
  is_contact = labels.loc[(labels['contact_id'] == contact_id) & (labels['contact'] == 1)]
  if len(is_contact) > 0:
    contact_true.append(contact_id)
  if c == 10000:
    print("10000")
  if c == 35000:
    print("35000")  
  if c > 66000:
    break

print("contact_True: ", len(contact_true))
#then get how many of 1.0, 1.67, 2.0, 3.0 are contact = 1 by contact_id label.contact_id = test_filtered.contact_id where contact = 1 or 0
print(len(test))
print(len(test_filtered))
'''

del test, labels, test_tracking
gc.collect()

"""**Albumentations Library**

[Docs](https://albumentations.ai/docs/getting_started/image_augmentation/)

@Article{info11020125,
    AUTHOR = {Buslaev, Alexander and Iglovikov, Vladimir I. and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A.},
    TITLE = {Albumentations: Fast and Flexible Image Augmentations},
    JOURNAL = {Information},
    VOLUME = {11},
    YEAR = {2020},
    NUMBER = {2},
    ARTICLE-NUMBER = {125},
    URL = {https://www.mdpi.com/2078-2489/11/2/125},
    ISSN = {2078-2489},
    DOI = {10.3390/info11020125}
}
"""

#can be tuned such as p value, brightness, contrast
train_aug = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(p=0.5),
    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),
    A.Normalize(mean=[0.], std=[1.]),
    ToTensorV2()
])

valid_aug = A.Compose([
    A.Normalize(mean=[0.], std=[1.]),
    ToTensorV2()
])

video2helmets = {}
test_helmets_new = test_helmets.set_index('video')
for video in tqdm(test_helmets.video.unique()):
    video2helmets[video] = test_helmets_new.loc[video].reset_index(drop=True)
    
del test_helmets, test_helmets_new
gc.collect()

video2frames = {}

for game_play in tqdm(test_video_metadata.game_play.unique()):
    for view in ['Endzone', 'Sideline']:
        video = game_play + f'_{view}.mp4'
        video2frames[video] = max(list(map(lambda x:int(x.split('_')[-1].split('.')[0]), \
                                           #glob.glob(f'/kaggle/work/frames/{video}*'))))
                                           glob.glob(f'/content/gdrive/My Drive/nfl-player-contact-detection/work/frames/{video}*'))))

class MyDataset(Dataset):
    def __init__(self, df, aug=valid_aug, mode='train'):
        self.df = df
        self.frame = df.frame.values
        self.feature = df[feature_cols].fillna(-1).values
        self.players = df[['nfl_player_id_1','nfl_player_id_2']].values
        self.game_play = df.game_play.values
        self.aug = aug
        self.mode = mode
        
    def __len__(self):
        return len(self.df)
    
    # @lru_cache(1024)
    # def read_img(self, path):
    #     return cv2.imread(path, 0)
   
    def __getitem__(self, idx):   
        window = 24
        frame = self.frame[idx]
        
        if self.mode == 'train':
            frame = frame + random.randint(-6, 6)

        players = []
        for p in self.players[idx]:
            if p == 'G':
                players.append(p)
            else:
                players.append(int(p))
        
        imgs = []
        for view in ['Endzone', 'Sideline']:
            video = self.game_play[idx] + f'_{view}.mp4'

            tmp = video2helmets[video]
#             tmp = tmp.query('@frame-@window<=frame<=@frame+@window')
            tmp[tmp['frame'].between(frame-window, frame+window)]
            tmp = tmp[tmp.nfl_player_id.isin(players)]#.sort_values(['nfl_player_id', 'frame'])
            tmp_frames = tmp.frame.values
            tmp = tmp.groupby('frame')[['left','width','top','height']].mean()
#0.002s

            bboxes = []
            for f in range(frame-window, frame+window+1, 1):
                if f in tmp_frames:
                    x, w, y, h = tmp.loc[f][['left','width','top','height']]
                    bboxes.append([x, w, y, h])
                else:
                    bboxes.append([np.nan, np.nan, np.nan, np.nan])
            bboxes = pd.DataFrame(bboxes).interpolate(limit_direction='both').values
            bboxes = bboxes[::4]

            if bboxes.sum() > 0:
                flag = 1
            else:
                flag = 0
#0.03s
                    
            for i, f in enumerate(range(frame-window, frame+window+1, 4)):
                img_new = np.zeros((256, 256), dtype=np.float32)

                if flag == 1 and f <= video2frames[video]:
                    #img = cv2.imread(f'/kaggle/work/frames/{video}_{f:04d}.jpg', 0)
                    img = cv2.imread(f'/content/gdrive/My Drive/nfl-player-contact-detection/work/frames/{video}_{f:04d}.jpg', 0)
                    x, w, y, h = bboxes[i]

                    img = img[int(y+h/2)-128:int(y+h/2)+128,int(x+w/2)-128:int(x+w/2)+128].copy()
                    img_new[:img.shape[0], :img.shape[1]] = img
                    
                imgs.append(img_new)
#0.06s
                
        feature = np.float32(self.feature[idx])

        img = np.array(imgs).transpose(1, 2, 0)    
        img = self.aug(image=img)["image"]
        label = np.float32(self.df.contact.values[idx])

        return img, feature, label

"""# **Cropped Image for point of contact**"""

img, feature, label = MyDataset(test_filtered, valid_aug, 'test')[0]
plt.imshow(img.permute(1,2,0)[:,:,7])
plt.show()
img.shape, feature, label

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.backbone = timm.create_model(CFG['model'], pretrained=False, num_classes=500, in_chans=13)
        self.mlp = nn.Sequential(
            nn.Linear(18, 64),
            nn.LayerNorm(64),
            nn.ReLU(),
            nn.Dropout(0.2),
            # nn.Linear(64, 64),
            # nn.LayerNorm(64),
            # nn.ReLU(),
            # nn.Dropout(0.2)
        )
        self.fc = nn.Linear(64+500*2, 1)

    def forward(self, img, feature):
        b, c, h, w = img.shape
        img = img.reshape(b*2, c//2, h, w)
        img = self.backbone(img).reshape(b, -1)
        feature = self.mlp(feature)
        y = self.fc(torch.cat([img, feature], dim=1))
        return y

test_set = MyDataset(test_filtered, valid_aug, 'test')
test_loader = DataLoader(test_set, batch_size=CFG['valid_bs'], shuffle=False, num_workers=CFG['num_workers'], pin_memory=True)

model = Model().to(device)
#model.load_state_dict(torch.load('/kaggle/input/nfl-exp1/resnet50_fold0.pt'))
model.load_state_dict(torch.load(data_dir + 'models/resnet50_fold0.pt'))

model.eval()
    
y_pred = []
with torch.no_grad():
    tk = tqdm(test_loader, total=len(test_loader))
    for step, batch in enumerate(tk):
        if(step % 4 != 3):
            img, feature, label = [x.to(device) for x in batch]
            output1 = model(img, feature).squeeze(-1)
            output2 = model(img.flip(-1), feature).squeeze(-1)
            
            y_pred.extend(0.2*(output1.sigmoid().cpu().numpy()) + 0.8*(output2.sigmoid().cpu().numpy()))
        else:
            img, feature, label = [x.to(device) for x in batch]
            output = model(img.flip(-1), feature).squeeze(-1)
            y_pred.extend(output.sigmoid().cpu().numpy())    

y_pred = np.array(y_pred)

th = 0.29

test_filtered['contact'] = (y_pred >= th).astype('int')

#sub = pd.read_csv('/kaggle/input/nfl-player-contact-detection/sample_submission.csv')
sub = pd.read_csv(data_dir + 'sample_submission.csv')
sub = sub.drop("contact", axis=1).merge(test_filtered[['contact_id', 'contact']], how='left', on='contact_id')
sub['contact'] = sub['contact'].fillna(0).astype('int')

sub[["contact_id", "contact"]].to_csv(data_dir + "submission1.csv", index=False)
len(sub)
sub.head()