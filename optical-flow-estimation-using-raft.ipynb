{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What's Optical flow?\n\n> Optical flow or optic flow is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. - https://en.wikipedia.org/wiki/Optical_flow\n\n\n**In this competition, each player motion can be essential for detecting the helmet impact. I'm going to introduce a deep learning model for optical flow estimation.**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('/kaggle/input/raft-pytorch')\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\n\nfrom glob import glob\nfrom PIL import Image\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RAFT introduction\n\nI introduce the model: **RAFT: Recurrent All-Pairs Field Transforms for Optical Flow** which is originally introduced in ECCV2020 by Teed et. al. in Princeton University and prized Best Paper Award!.\n* https://arxiv.org/abs/2003.12039\n* https://github.com/princeton-vl/RAFT (licensed under the BSD 3-Clause License)\n\nBriefly, RAFT has below features\n* Recurrent optical flow estimation\n* Compute pixel-wise correlation between pair-wise input images and reuse it in the following recurrent step\n* Lightweight, rapid inference, and high accuracy\n\n![RAFT architecture image from https://github.com/princeton-vl/RAFT](https://github.com/princeton-vl/RAFT/raw/master/RAFT.png)\n\nThis is [my explanation slide](https://speakerdeck.com/daigo0927/raft-recurrent-all-pairs-field-transforms-for-optical-flow) in Japanese.","metadata":{}},{"cell_type":"markdown","source":"# Run RAFT on sample images","metadata":{}},{"cell_type":"code","source":"from raft.core.raft import RAFT\nfrom raft.core.utils import flow_viz\nfrom raft.core.utils.utils import InputPadder\nfrom raft.config import RAFTConfig","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = RAFTConfig(\n    dropout=0,\n    alternate_corr=False,\n    small=False,\n    mixed_precision=False\n)\n\nmodel = RAFT(config)\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'device: {device}')\n\nweights_path = '/kaggle/input/raft-pytorch/raft-sintel.pth'\n# weights_path = '/kaggle/input/raft-pytorch/raft-things.pth'\n\nckpt = torch.load(weights_path, map_location=device)\nmodel.to(device)\nmodel.load_state_dict(ckpt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_files = glob('/kaggle/input/raft-pytorch/raft/demo-frames/*.png')\nimage_files = sorted(image_files)\n\nprint(f'Found {len(image_files)} images')\nprint(sorted(image_files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(imfile, device):\n    img = np.array(Image.open(imfile)).astype(np.uint8)\n    img = torch.from_numpy(img).permute(2, 0, 1).float()\n    return img[None].to(device)\n\n\ndef viz(img1, img2, flo):\n    img1 = img1[0].permute(1,2,0).cpu().numpy()\n    img2 = img2[0].permute(1,2,0).cpu().numpy()\n    flo = flo[0].permute(1,2,0).cpu().numpy()\n    \n    # map flow to rgb image\n    flo = flow_viz.flow_to_image(flo)\n    \n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n    ax1.set_title('input image1')\n    ax1.imshow(img1.astype(int))\n    ax2.set_title('input image2')\n    ax2.imshow(img2.astype(int))\n    ax3.set_title('estimated optical flow')\n    ax3.imshow(flo)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nn_vis = 3\n\nfor file1, file2 in tqdm(zip(image_files[:n_vis], image_files[1:1+n_vis])):\n    image1 = load_image(file1, device)\n    image2 = load_image(file2, device)\n\n    padder = InputPadder(image1.shape)\n    image1, image2 = padder.pad(image1, image2)\n    \n    with torch.no_grad():\n        flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n        \n    viz(image1, image2, flow_up)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first and second columns are input paired images and right column is the predicted optical flow.","metadata":{}},{"cell_type":"markdown","source":"# Run on NFL video","metadata":{}},{"cell_type":"code","source":"video_file = '/kaggle/input/nfl-impact-detection/train/57583_000082_Endzone.mp4'\n\ncap = cv2.VideoCapture(video_file)\n\nframes = []\nwhile True:\n    has_frame, image = cap.read()\n    \n    if has_frame:\n        image = image[:, :, ::-1] # convert BGR -> RGB\n        frames.append(image)\n    else:\n        break\nframes = np.stack(frames, axis=0)\n\nprint(f'frame shape: {frames.shape}')    \nplt.imshow(frames[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_vis = 3\n\nfor i in range(n_vis):\n    image1 = torch.from_numpy(frames[i]).permute(2, 0, 1).float().to(device)\n    image2 = torch.from_numpy(frames[i+1]).permute(2, 0, 1).float().to(device)\n    \n    image1 = image1[None].to(device)\n    image2 = image2[None].to(device)\n\n    padder = InputPadder(image1.shape)\n    image1, image2 = padder.pad(image1, image2)\n    \n    with torch.no_grad():\n        flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n        \n    viz(image1, image2, flow_up)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RAFT seems to capture the motion of each player.","metadata":{}},{"cell_type":"markdown","source":"# Have a nice football flow!","metadata":{}}]}